# Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# NOTE: This file is auto generated by the elixir code generator program.
# Do not edit this file manually.

defmodule GoogleApi.VideoIntelligence.V1.Model.GoogleCloudVideointelligenceV1_SpeechTranscriptionConfig do
  @moduledoc """
  Config for SPEECH_TRANSCRIPTION.

  ## Attributes

  *   `audioTracks` (*type:* `list(integer())`, *default:* `nil`) - *Optional* For file formats, such as MXF or MKV, supporting multiple audio
      tracks, specify up to two tracks. Default: track 0.
  *   `diarizationSpeakerCount` (*type:* `integer()`, *default:* `nil`) - *Optional*
      If set, specifies the estimated number of speakers in the conversation.
      If not set, defaults to '2'.
      Ignored unless enable_speaker_diarization is set to true.
  *   `enableAutomaticPunctuation` (*type:* `boolean()`, *default:* `nil`) - *Optional* If 'true', adds punctuation to recognition result hypotheses.
      This feature is only available in select languages. Setting this for
      requests in other languages has no effect at all. The default 'false' value
      does not add punctuation to result hypotheses. NOTE: "This is currently
      offered as an experimental service, complimentary to all users. In the
      future this may be exclusively available as a premium feature."
  *   `enableSpeakerDiarization` (*type:* `boolean()`, *default:* `nil`) - *Optional* If 'true', enables speaker detection for each recognized word in
      the top alternative of the recognition result using a speaker_tag provided
      in the WordInfo.
      Note: When this is true, we send all the words from the beginning of the
      audio for the top alternative in every consecutive responses.
      This is done in order to improve our speaker tags as our models learn to
      identify the speakers in the conversation over time.
  *   `enableWordConfidence` (*type:* `boolean()`, *default:* `nil`) - *Optional* If `true`, the top result includes a list of words and the
      confidence for those words. If `false`, no word-level confidence
      information is returned. The default is `false`.
  *   `filterProfanity` (*type:* `boolean()`, *default:* `nil`) - *Optional* If set to `true`, the server will attempt to filter out
      profanities, replacing all but the initial character in each filtered word
      with asterisks, e.g. "f***". If set to `false` or omitted, profanities
      won't be filtered out.
  *   `languageCode` (*type:* `String.t`, *default:* `nil`) - *Required* The language of the supplied audio as a
      [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
      Example: "en-US".
      See [Language Support](https://cloud.google.com/speech/docs/languages)
      for a list of the currently supported language codes.
  *   `maxAlternatives` (*type:* `integer()`, *default:* `nil`) - *Optional* Maximum number of recognition hypotheses to be returned.
      Specifically, the maximum number of `SpeechRecognitionAlternative` messages
      within each `SpeechTranscription`. The server may return fewer than
      `max_alternatives`. Valid values are `0`-`30`. A value of `0` or `1` will
      return a maximum of one. If omitted, will return a maximum of one.
  *   `speechContexts` (*type:* `list(GoogleApi.VideoIntelligence.V1.Model.GoogleCloudVideointelligenceV1_SpeechContext.t)`, *default:* `nil`) - *Optional* A means to provide context to assist the speech recognition.
  """

  use GoogleApi.Gax.ModelBase

  @type t :: %__MODULE__{
          :audioTracks => list(integer()),
          :diarizationSpeakerCount => integer(),
          :enableAutomaticPunctuation => boolean(),
          :enableSpeakerDiarization => boolean(),
          :enableWordConfidence => boolean(),
          :filterProfanity => boolean(),
          :languageCode => String.t(),
          :maxAlternatives => integer(),
          :speechContexts =>
            list(
              GoogleApi.VideoIntelligence.V1.Model.GoogleCloudVideointelligenceV1_SpeechContext.t()
            )
        }

  field(:audioTracks, type: :list)
  field(:diarizationSpeakerCount)
  field(:enableAutomaticPunctuation)
  field(:enableSpeakerDiarization)
  field(:enableWordConfidence)
  field(:filterProfanity)
  field(:languageCode)
  field(:maxAlternatives)

  field(
    :speechContexts,
    as: GoogleApi.VideoIntelligence.V1.Model.GoogleCloudVideointelligenceV1_SpeechContext,
    type: :list
  )
end

defimpl Poison.Decoder,
  for:
    GoogleApi.VideoIntelligence.V1.Model.GoogleCloudVideointelligenceV1_SpeechTranscriptionConfig do
  def decode(value, options) do
    GoogleApi.VideoIntelligence.V1.Model.GoogleCloudVideointelligenceV1_SpeechTranscriptionConfig.decode(
      value,
      options
    )
  end
end

defimpl Poison.Encoder,
  for:
    GoogleApi.VideoIntelligence.V1.Model.GoogleCloudVideointelligenceV1_SpeechTranscriptionConfig do
  def encode(value, options) do
    GoogleApi.Gax.ModelBase.encode(value, options)
  end
end
